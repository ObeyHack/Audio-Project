{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# import dataset",
   "id": "fc54dcfd26dad28c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-03T13:13:42.093710Z",
     "start_time": "2024-08-03T13:13:25.279941Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"SLPRL-HUJI/HebDB\", \"YV_pre\", split='train', streaming=True, cache_dir='datasets')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/608 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0bfcfd0c0b6448bd9f1d470dfa5341a3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T13:14:01.556599Z",
     "start_time": "2024-08-03T13:14:01.545595Z"
    }
   },
   "cell_type": "code",
   "source": "dataset.features",
   "id": "56d17a0fccd11723",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fname': Value(dtype='string', id=None),\n",
       " 'audio': Audio(sampling_rate=None, mono=True, decode=True, id=None),\n",
       " 'n_samples': Value(dtype='int64', id=None),\n",
       " 'text': Value(dtype='string', id=None),\n",
       " 'normalized_text': Value(dtype='string', id=None),\n",
       " 'score': Value(dtype='float64', id=None),\n",
       " 'raw': {'end_sec': Value(dtype='float64', id=None),\n",
       "  'fname': Value(dtype='string', id=None),\n",
       "  'start_sec': Value(dtype='float64', id=None)},\n",
       " 'is_raw': Value(dtype='bool', id=None),\n",
       " 'source': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T13:14:03.335525Z",
     "start_time": "2024-08-03T13:14:03.317528Z"
    }
   },
   "cell_type": "code",
   "source": "print(dataset.take(1))",
   "id": "89a2d1dc5ecd95ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IterableDataset({\n",
      "    features: ['fname', 'audio', 'n_samples', 'text', 'normalized_text', 'score', 'raw', 'is_raw', 'source'],\n",
      "    n_shards: 15\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Preprocessing"
   ],
   "id": "4988dde7d66a8d42"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T13:14:05.408301Z",
     "start_time": "2024-08-03T13:14:04.582263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-multilingual-cased')"
   ],
   "id": "f4a42de1a84e0a3e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T13:23:06.060076Z",
     "start_time": "2024-08-03T13:23:06.053057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenization(examples):\n",
    "    print('tokenization')\n",
    "    examples[\"normalized_text2\"] = tokenizer(examples[\"normalized_text\"], padding=\"max_length\")"
   ],
   "id": "e7d5f61655e474e1",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T13:23:04.476468Z",
     "start_time": "2024-08-03T13:23:04.457470Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_pre = dataset.map(tokenization, batched=True)",
   "id": "9804ad60d8c5ba9d",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T13:14:08.567674Z",
     "start_time": "2024-08-03T13:14:08.556654Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_pre = dataset_pre.with_format(\"torch\")",
   "id": "9e6eede1a14a9846",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T13:14:10.329180Z",
     "start_time": "2024-08-03T13:14:10.317182Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_pre.features",
   "id": "14a40efdacdbd6cf",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Dataloader"
   ],
   "id": "f0bf7e7431b7bcbf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T13:14:16.310568Z",
     "start_time": "2024-08-03T13:14:15.650551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorForLanguageModeling"
   ],
   "id": "784d1ed38af04671",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T13:26:43.137889Z",
     "start_time": "2024-08-03T13:26:09.256311Z"
    }
   },
   "cell_type": "code",
   "source": "dataloader = DataLoader(dataset, collate_fn=DataCollatorForLanguageModeling(tokenizer))",
   "id": "11c380b8ec90622e",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m dataloader \u001B[38;5;241m=\u001B[39m \u001B[43mDataLoader\u001B[49m(dataset, collate_fn\u001B[38;5;241m=\u001B[39mDataCollatorForLanguageModeling(tokenizer))\n",
      "Cell \u001B[1;32mIn[22], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m dataloader \u001B[38;5;241m=\u001B[39m \u001B[43mDataLoader\u001B[49m(dataset, collate_fn\u001B[38;5;241m=\u001B[39mDataCollatorForLanguageModeling(tokenizer))\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:1187\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:627\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:937\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:928\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:585\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\PyCharm Professional\\plugins\\python\\helpers\\pydev\\pydevd.py:1201\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1198\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1200\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1201\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\PyCharm Professional\\plugins\\python\\helpers\\pydev\\pydevd.py:1216\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1213\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1215\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1216\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1218\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1220\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T13:18:52.266505Z",
     "start_time": "2024-08-03T13:16:22.425700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "    break"
   ],
   "id": "d918ffaabb959478",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['fname', 'audio', 'n_samples', 'text', 'normalized_text', 'score', 'raw', 'is_raw', 'source']",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m dataloader:\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;28mprint\u001B[39m(batch)\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Documents\\GitHub\\Audio-Project\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32mD:\\Documents\\GitHub\\Audio-Project\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    671\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    672\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 673\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    674\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    675\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32mD:\\Documents\\GitHub\\Audio-Project\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:43\u001B[0m, in \u001B[0;36m_IterableDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     42\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset_iter)\n\u001B[1;32m---> 43\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Documents\\GitHub\\Audio-Project\\.venv\\lib\\site-packages\\transformers\\data\\data_collator.py:45\u001B[0m, in \u001B[0;36mDataCollatorMixin.__call__\u001B[1;34m(self, features, return_tensors)\u001B[0m\n\u001B[0;32m     43\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtf_call(features)\n\u001B[0;32m     44\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m return_tensors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m---> 45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtorch_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m return_tensors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnp\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m     47\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnumpy_call(features)\n",
      "File \u001B[1;32mD:\\Documents\\GitHub\\Audio-Project\\.venv\\lib\\site-packages\\transformers\\data\\data_collator.py:806\u001B[0m, in \u001B[0;36mDataCollatorForLanguageModeling.torch_call\u001B[1;34m(self, examples)\u001B[0m\n\u001B[0;32m    803\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtorch_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, examples: List[Union[List[\u001B[38;5;28mint\u001B[39m], Any, Dict[\u001B[38;5;28mstr\u001B[39m, Any]]]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, Any]:\n\u001B[0;32m    804\u001B[0m     \u001B[38;5;66;03m# Handle dict or lists with proper padding and conversion to tensor.\u001B[39;00m\n\u001B[0;32m    805\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(examples[\u001B[38;5;241m0\u001B[39m], Mapping):\n\u001B[1;32m--> 806\u001B[0m         batch \u001B[38;5;241m=\u001B[39m \u001B[43mpad_without_fast_tokenizer_warning\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    807\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad_to_multiple_of\u001B[49m\n\u001B[0;32m    808\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    809\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    810\u001B[0m         batch \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    811\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m: _torch_collate_batch(examples, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer, pad_to_multiple_of\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpad_to_multiple_of)\n\u001B[0;32m    812\u001B[0m         }\n",
      "File \u001B[1;32mD:\\Documents\\GitHub\\Audio-Project\\.venv\\lib\\site-packages\\transformers\\data\\data_collator.py:66\u001B[0m, in \u001B[0;36mpad_without_fast_tokenizer_warning\u001B[1;34m(tokenizer, *pad_args, **pad_kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m tokenizer\u001B[38;5;241m.\u001B[39mdeprecation_warnings[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAsking-to-pad-a-fast-tokenizer\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 66\u001B[0m     padded \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;241m*\u001B[39mpad_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpad_kwargs)\n\u001B[0;32m     67\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# Restore the state of the warning.\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     tokenizer\u001B[38;5;241m.\u001B[39mdeprecation_warnings[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAsking-to-pad-a-fast-tokenizer\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m warning_state\n",
      "File \u001B[1;32mD:\\Documents\\GitHub\\Audio-Project\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3497\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.pad\u001B[1;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001B[0m\n\u001B[0;32m   3495\u001B[0m \u001B[38;5;66;03m# The model's main input name, usually `input_ids`, has be passed for padding\u001B[39;00m\n\u001B[0;32m   3496\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_input_names[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m encoded_inputs:\n\u001B[1;32m-> 3497\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   3498\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou should supply an encoding or a list of encodings to this method \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3499\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthat includes \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_input_names[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, but you provided \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(encoded_inputs\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3500\u001B[0m     )\n\u001B[0;32m   3502\u001B[0m required_input \u001B[38;5;241m=\u001B[39m encoded_inputs[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_input_names[\u001B[38;5;241m0\u001B[39m]]\n\u001B[0;32m   3504\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m required_input \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m (\u001B[38;5;28misinstance\u001B[39m(required_input, Sized) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(required_input) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m):\n",
      "\u001B[1;31mValueError\u001B[0m: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['fname', 'audio', 'n_samples', 'text', 'normalized_text', 'score', 'raw', 'is_raw', 'source']"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
